{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2162d847-f0b2-4693-ad9f-d0f9c311049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abyssinian_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filename = 'Abyssinian_1.jpg'\n",
    "extension = os.path.splitext(filename)[1]\n",
    "label = filename.replace(extension, '')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1e3f68-c99b-42f4-807b-546a54fb4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pomeranian_39.jpg', 0, 'pomeranian']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_input = os.path.join('data/pets/images')\n",
    "list_filename = os.listdir(path_input)\n",
    "\n",
    "list_filenames = os.listdir(path_input)\n",
    "list_file = []\n",
    "for filename in list_filenames:\n",
    "    if ('newfoundland' in filename) or ('pomeranian' in filename):\n",
    "        label = 0 # dog\n",
    "    elif ('Abyssinian' in filename) or ('Bombay' in filename):\n",
    "        label = 1 # cat\n",
    "    else:\n",
    "        continue\n",
    "    list_file.append([filename, label, filename.split('_')[0]])\n",
    "print(list_file[0])\n",
    "# ['Abyssinian_1.jpg', 1, 'Abyssinian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab14d36-171c-44b5-828e-6edcc5fb020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "list_train, list_val = train_test_split(list_file, shuffle=True, random_state=random_seed, test_size=0.2)\n",
    "list_val, list_test = train_test_split(list_val, shuffle=True, random_state=random_seed, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df26c6c8-8683-4f77-b41d-a4bae9a1e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, list_file, transform=None, phase='train'):\n",
    "        self.list_file = list_file\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        # ファイル数を返す\n",
    "        return len(self.list_file)\n",
    "\n",
    "    # def __getitem__(self, index):\n",
    "    #     # 画像をPillowsで開く\n",
    "    #     path_input = './data/pets/images/'\n",
    "    #     path_image = os.path.join(path_input, self.list_file[index][0])\n",
    "    #     pil_image = Image.open(path_image)\n",
    "\n",
    "    #     # 画像の前処理\n",
    "    #     image_transformed = self.transform(pil_image).convert('RGB')\n",
    "\n",
    "    #     # ラベルを取得\n",
    "    #     label_class = self.list_file[index][1]\n",
    "    #     label_type = self.list_file[index][2]\n",
    "    #     return image_transformed, label_class\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_input = './data/pets/images/'\n",
    "        path_image = os.path.join(path_input, self.list_file[index][0])\n",
    "        pil_image = Image.open(path_image).convert('RGB') # <-- ここでPILのままRGBに変換\n",
    "        \n",
    "        # 画像の前処理\n",
    "        image_transformed = self.transform(pil_image) # <-- transformがTensorに変換する\n",
    "        \n",
    "        # ラベルを取得\n",
    "        label_class = self.list_file[index][1]\n",
    "        label_type = self.list_file[index][2]\n",
    "        \n",
    "        return image_transformed, label_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf04382b-cbd4-4071-8a6b-410a8b761247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class ImageTransform():\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.Resize(resize),\n",
    "            transforms.CenterCrop(resize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.data_transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c06aed1-5604-4a48-82f0-30af441dbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "transform = ImageTransform(resize, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bbb345-31a6-4742-9135-259a42a09df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "train_dataset = MyDataset(list_train, transform=transform, phase='train')\n",
    "val_dataset = MyDataset(list_val, transform=transform, phase='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62d3357-abe9-41f6-831c-5ec26913a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0b8079e-e24b-4b70-8873-c7683e9fd554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# デバイスを選択\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df4a193-9b7d-46c4-8257-0c47f0b51fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "net = models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')\n",
    "# 出力層を2つに付け替える\n",
    "\n",
    "import torch.nn as nn\n",
    "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60019c03-1e15-4009-a854-78cd35de87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 損失関数の定義\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feebd027-28ad-45ce-9d4a-9ee784eee916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "lr = 0.001\n",
    "USE_FINE_TUNING = True\n",
    "# 最適化手法の選択\n",
    "if USE_FINE_TUNING:\n",
    "    # 最適化手法を設定\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "else:\n",
    "    # 転移学習\n",
    "    params_to_update = []\n",
    "    update_param_names = ['classifier.6.weight', 'classifier.6.bias']\n",
    "    for name, param in net.named_parameters():\n",
    "        if name in update_param_names:\n",
    "            param.requires_grad = True\n",
    "            params_to_update.append(param)\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "        optimizer = optim.Adam(params=params_to_update, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dcc3b02-342b-4052-abb3-528e0494be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def validation(net, device, criterion, val_dataloader):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    Y = []\n",
    "    preds = []\n",
    "    with tqdm(total=len(val_dataloader)) as pbar:\n",
    "        pbar.set_description('validation')\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, pred = torch.max(outputs, 1) # ラベルの予想\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            # Y.extend(labels)\n",
    "            # preds.extend(pred)\n",
    "\n",
    "            Y.extend(labels.cpu().tolist())\n",
    "            preds.extend(pred.cpu().tolist())\n",
    "\n",
    "            pbar.update(1)\n",
    "    return accuracy_score(y_true=Y, y_pred=preds), total_loss, Y, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633c2ae-7976-47d1-9fe9-14129df911d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  10%|███████▍                                                                    | 98/1000 [00:05<00:46, 19.31it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 39.34it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 42.68it/s]\u001b[A\n",
      "training:  20%|██████████████▊                                                            | 197/1000 [00:10<00:41, 19.44it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 47.02it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 44.47it/s]\u001b[A\n",
      "training:  30%|██████████████████████▍                                                    | 299/1000 [00:15<00:35, 19.74it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 47.99it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 44.46it/s]\u001b[A\n",
      "training:  40%|█████████████████████████████▊                                             | 397/1000 [00:21<00:30, 19.56it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 42.76it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 43.49it/s]\u001b[A\n",
      "training:  50%|█████████████████████████████████████▎                                     | 498/1000 [00:26<00:26, 18.92it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 41.02it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 41.69it/s]\u001b[A\n",
      "training:  60%|████████████████████████████████████████████▊                              | 598/1000 [00:32<00:20, 19.27it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 41.40it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 42.60it/s]\u001b[A\n",
      "training:  70%|████████████████████████████████████████████████████▎                      | 698/1000 [00:37<00:15, 19.60it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 40.70it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 41.63it/s]\u001b[A\n",
      "training:  80%|███████████████████████████████████████████████████████████▊               | 798/1000 [00:43<00:10, 19.14it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 45.95it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 43.75it/s]\u001b[A\n",
      "training:  90%|███████████████████████████████████████████████████████████████████▎       | 897/1000 [00:48<00:05, 19.27it/s]\n",
      "  0%|                                                                                                 | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "validation:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 42.55it/s]\u001b[A\n",
      "validation: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 42.88it/s]\u001b[A\n",
      "training:  96%|████████████████████████████████████████████████████████████████████████   | 961/1000 [00:52<00:02, 19.17it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "count = 0\n",
    "iteration = 0\n",
    "total_loss = 0\n",
    "max_itr = 1000\n",
    "val_interval = 100\n",
    "path_save_logfile_train = \"/home/cygnus/fujimoto/Cygnus-X_Molecular_Cloud_Analysis/Cygnus-X_cloud/Binary_classification/path_save_logfile_train.txt\"\n",
    "path_save_logfile_val = \"/home/cygnus/fujimoto/Cygnus-X_Molecular_Cloud_Analysis/Cygnus-X_cloud/Binary_classification/path_save_logfile_val.txt\"\n",
    "\n",
    "Y_train = []\n",
    "pred_train = []\n",
    "time_trainval_total_start = time.perf_counter()\n",
    "with tqdm(total=max_itr) as pbar:\n",
    "    pbar.set_description('training')\n",
    "    while iteration < max_itr:\n",
    "        for inputs, labels in train_dataloader:\n",
    "            if iteration >= max_itr:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if count == 0:\n",
    "                net.train()\n",
    "                time_trainval_interval_start = time.perf_counter()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, pred = torch.max(outputs, 1) # ラベルの予測\n",
    "\n",
    "                # バックプロパゲーション\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # カウント\n",
    "            count += 1\n",
    "            iteration += 1\n",
    "            # 損失計算\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            # スコア計算用\n",
    "            # Y_train.extend(labels)\n",
    "            # pred_train.extend(pred)\n",
    "            Y_train.extend(labels.cpu().tolist())\n",
    "            pred_train.extend(pred.cpu().tolist())\n",
    "\n",
    "            if count == val_interval:\n",
    "                time_trainval_interval_end = time.perf_counter()\n",
    "                time_trainval_interval = time_trainval_interval_end - time_trainval_interval_start\n",
    "                total_loss = total_loss / val_interval\n",
    "                # validation\n",
    "                acc_score, loss_val, Y, preds = validation(net, device=device, criterion=criterion, val_dataloader=val_dataloader)\n",
    "                # save log\n",
    "                ## training\n",
    "                with open(path_save_logfile_train, 'a') as logfile:\n",
    "                    logfile.write('{},{},{},{}\\n'.format(iteration, time_trainval_interval, total_loss, accuracy_score(y_true=Y_train, y_pred=pred_train)))\n",
    "                ## validation\n",
    "                with open(path_save_logfile_val, 'a') as logfile:\n",
    "                    logfile.write('{},{},{},{}\\n'.format(iteration, time_trainval_interval, loss_val, acc_score))\n",
    "\n",
    "                # 結果の描画\n",
    "\n",
    "                # reset\n",
    "                count = 0\n",
    "                Y_train = []\n",
    "                pred_train = []\n",
    "\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84164490-c6f1-43b1-9aae-bf2b23946524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
